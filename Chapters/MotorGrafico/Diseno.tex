\section{Diseño y estructura del motor}
\label{engine_design}
Antes de empezar a trabajar es necesario conocer cómo comunicar la aplicación con Manta, el motor gráfico que será utilizado para el desarrollo, y tener al menos una buena idea del modo en que el motor tratará la información que le proporcionemos.

La aplicación final estará dividida en tres partes importantes: la aplicación en sí, el framework, y el núcleo o core (fig. \ref{fig:estructura_app}).

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.70]{estructura_app}
    \caption{Estructura de la aplicación.}
    \label{fig:estructura_app}
\end{figure}

En el momento de manejar la escena, la aplicación en ningún momento se comunicará directamente con el núcleo del motor, sino que lo hará a través del framework. El framework está diseñado para facilitar la usabilidad, mientras que el núcleo prioriza la eficiencia, de modo que utilizando este sistema no se renuncia a ninguna de las dos cosas.

Otros elementos más sencillos del núcleo sí son accesibles desde la aplicación, como el gestor de memoria o la carga de materiales y texturas.

\subsection{Ratio de fotogramas por segundo y bucle de ejecución}
\label{fps_bucle_ejecucion}
Aunque puede funcionar para la generación de imágenes estáticas, Manta es sobretodo un motor gráfico en tiempo real. Esto significa que su código se ejecuta múltiples veces para generar imágenes distintas y mostrarlas en pantalla, con lo cual se logra una ilusión de movimiento. De manera óptima suele considerarse como estándar los 60 fotogramas por segundo\footfullcite{vsync_nvidia} (FPS o frames en adelante), aunque 24-30 FPS suele considerarse el mínimo aceptable. Debe tenerse en cuenta que aunque estos son los valores habituales, la tolerancia varía según el tipo de aplicación: en nuestro caso aunque buscamos una respuesta fluida, puede llegar a ser aceptable una bajada de los FPS sin afectar gravemente la experiencia de usuario.

Como implicación está que para una buena experiencia en tiempo real todos los aspectos de la aplicación, incluyendo los cálculos de la propia aplicación como del propio motor y el renderizado a través de la GPU, deben calcularse como mínimo en unos 40 milisegundos segundos y óptimamente en 16 milisegundos (los mencionados 24 y 60 FPS). En contraste, un render de alta calidad con ray tracing (una técnica que simula la física detrás de la interacción entre la luz y las superficies de un espacio) puede tardar varios minutos u horas\footfullcite{nvidia_raytr}. Es de esperar por tanto que el motor sacrifique gran parte de ese realismo para reducir el tiempo de ejecución.

Para hacer esto repetidamente de manera indefinida se encapsula todo el código del programa en un bucle de infinito que sólo puede detenerse manualmente y que contiene, en orden:

\begin{itemize}
    \item El cálculo del tiempo de ejecución del frame: las variaciones de FPS que puedan producirse a lo largo de la ejecución pueden provocar un efecto de aceleración y deceleración que empeora notablemente la experiencia. Además no se puede predecir cual será el ratio de FPS al que se ejecutará la aplicación cuando no conocemos en qué máquina se ejecutará y cual es su potencia. Para evitar este tipo de indeterminación se calcula el tiempo que transcurre entre un frame y el siguiente, el cual puede utilizarse en los cálculos a la hora de actualizar para compensar.
    \item La actualización de la aplicación: se llama a una función desde la cual debemos actualizar la escena en función de los cálculos que se realicen. Cuando la aplicación alcance cierta complejidad, este puede llegar a ser el punto del bucle que absorba una mayor carga de trabajo, por lo que la eficiencia debe ser tenida en cuenta al actualizar para no ralentizar demasiado el programa.
    \item La actualización de la escena: Como se mencionará en el apartado \ref{scene_hierarchy}, el motor dispone de una colección de elementos que le hemos ordenado mostrar en pantalla. En este punto se actualiza la escena para que refleje los cambios hechos en el proceso de actualización de la aplicación. Entre otras cosas, se calculan las transformaciones de las entidades (\ref{entity_component}) y se prepara toda la información que pueda necesitarse para renderizar.
    \item Renderizado: En el momento de renderizar la escena, junto con la orden de renderizado se envía toda la información necesaria a la GPU (incluyendo la cámara, las luces y los elementos de la escena). Aquí predomina el funcionamiento de la API gráfica, por lo que según la plataforma en que nos encontremos, este paso será realizado por una API diferente (véase el apartado \ref{APIS}).
\end{itemize}

Previamente al bucle se ejecutan las funciones de inicialización tanto del motor como de la aplicación, mientras que al detener la ejecución se libera la memoria reservada (normalmente durante esta primera inicialización).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{Bucle}
    \caption{Esquema del bucle de ejecución.}
    \label{fig:bucle}
\end{figure}

\subsection{Patrón de entidad-componente}
\label{entity_component}
En una aplicación 3D, puede entenderse como entidad cualquier elemento que se encuentre en la escena. Por lo general todas tienen un elemento en común: tienen una transformación que indica su traslación, rotación y escalado. Sin embargo, cada entidad puede tener propósitos distintos: algunas son luces, otras cámaras, o objetos tridimensionales con malla y material, etc.

Dentro de cada categoría pueden haber varios tipos, o tal vez se necesita que una entidad cumpla unas propiedades determinadas como emitir audio o verse afectada por un motor de físicas; y también se podrían querer combinaciones de estas como que un elemento sea una luz y al mismo tiempo se balancee mediante un motor de físicas.

No es deseable que el código mezcle cosas tan dispares, tener las físicas y el audio en el mismo sitio resultaría en un código imposible de mantener a largo plazo; por lo que se precisa buscar un modo de modularizar estas características. Para ello existe el patrón entidad-componente\footfullcite{game_programming_patterns}, que nos permite crear componentes que aglomeran ciertas propiedades y comportamientos. Después podemos añadir cuantos componentes queramos a una entidad, permitiendo hacer que esta cumpla dichas propiedades sin aglomerar todo el código de estas.

Para implementar este patrón existen dos clases principales: ``Entity" y ``Component" (fig. \ref{fig:entity_component_structure}); las cuales pueden extenderse como se desee (no sólo desde el framework sino también desde la propia aplicación) para crear distintos tipos de cada una. Una entidad por defecto contiene una lista de componentes, que en el fondo son instancias de los diferentes tipos de componentes que creemos. Component es una clase abstracta y sus clases derivadas deben implementar uno o varios métodos que puedan ser llamados desde la entidad.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.75]{entity_component}
    \caption{Esquema simplificado del patrón entidad-componente.}
    \label{fig:entity_component_structure}
\end{figure}

De este modo, cada vez que la entidad necesite delegar una funcionalidad a sus componentes, iterará sobre ellos y llamará dichos métodos, que tendrán un comportamiento distinto según se requiera. En nuestro caso, los métodos que implementa Component son los siguientes:

\begin{itemize}
    \item AddedToEntity: Llamado en el momento en que se incorpora el componente a la entidad.
    \item RemovedFromEntity: Llamado en el momento en que este se borra de la entidad (lo cual normalmente significa que estamos eliminando la entidad, pero no necesariamente).
    \item AddedComponent: Se llama a todos los componentes que tenga la entidad cada vez que se añade uno nuevo, e incluye una referencia por parámetro del componente añadido.
    \item RemovedComponent: Al igual que la anterior, cuando se elimina un componente también se hace saber al resto de componentes aún existentes.
\end{itemize}

Aunque no ha sido utilizado, es bastante típico en el patrón Component tener un método ``update" que se llama en cada actualización de la aplicación (\ref{fps_bucle_ejecucion}) y hace que las propias entidades se encarguen de su propio comportamiento en tiempo real, a través de los componentes. En esta aplicación se ha decidido que sean funciones externas quienes controlen dicho comportamiento, y no las propias entidades.

Para acceder externamente a los componentes, en la clase Entity se hace uso de ``templates" de C++, sobre los cuales no se profundizará. Los templates permiten implementar un método independientemente del tipo de las variables con las que trabaja, de modo que este tipo se especifica en el momento de llamar al método. Para pedirle a una entidad que un componente específico, se debe especificar el tipo del componente que se desea.

\subsection{Escena, jerarquía y pasos previos al renderizado}
\label{scene_hierarchy}
Como se ha mencionado en el apartado \ref{entity_component}, existen una serie de entidades distribuidas por el espacio con una traslación, rotación y escalado. Este espacio se conoce como la escena.

Al crear una entidad, esta automáticamente se registra a sí misma en la jerarquía de la escena. La jerarquía contiene por tanto un listado con punteros a cada una de las entidades que le permite acceder a sus componentes. El motor trabaja directamente con este listado de objetos y hará automáticamente todo lo que se requiera con ellos en función de sus componentes. Por lo tanto, el usuario no debe pedir en ningún momento que se rendericen los objetos: basta con crear una entidad que tenga un componente de malla (véase el apartado \ref{mesh_light_cam}) para que el motor entienda que deberá renderizarlo.

Las entidades están organizadas en la jerarquía de tal modo que una entidad puede ser padre de otras entidades, formando una estructura de árbol. Las transformaciones de las entidades se acumulan desde la raíz de la jerarquía hacia abajo, es decir: si una entidad está desplazada o rotada, sus entidades ``hijas" tendrán una traslación y rotación respecto a la primera. Esto permite crear diferentes estructuras dentro de la escena y trabajar con estas sin tener que controlar la posición de todos los elementos que la componen. Por ejemplo: dada una entidad ``coche" y otra entidad ``asientos" asignar el primero como padre de los segundos hará que se mantengan en su sitio, pegados a la estructura del coche, dado que su transformación es relativa a este.

Una consecuencia de este sistema es que las transformaciones que hay en cada entidad no son realmente la transformación respecto al centro de la escena, que es la que necesitamos en el momento de renderizar. Por lo que se debe realizar un cálculo previo al renderizado que consiste en multiplicar de forma acumulativa las transformaciones en cada una de las ramas de la escena y asignarlas a cada uno de los elementos.

Aunque desde fuera la información se nos presente de en forma de árbol, internamente los datos están estructurados en arrays. El objetivo de esta estructura es mejorar la eficiencia del código (haciendo uso de conceptos como Data Oriented Design o SIMD, sobre los que no se profundizará en este documento pero pueden ser una buena lectura complementaria) sin sacrificar usabilidad.

\subsection{Mallas, luces y cámara}
\label{mesh_light_cam}
Se trata de los ejemplos más importantes de componentes (véase el apartado \ref{entity_component}) que se utilizan en el motor.

\subsubsection{Mallas}
Entendemos por malla (o mesh) un listado de vértices conectados por otro listado de índices. Los vértices contienen información de la posición, normal, tangente, bitangente y coordenadas UV (véase \ref{materials}) mientras que los índices simplemente ordenan los vértices de 3 en 3 creando triángulos. Los componentes ``MeshComponent" y ``MeshDynamicComponent" recogen esta información para que el motor renderice el resultado posteriormente. Estos componentes también incluyen los materiales de las mallas.

La diferencia principal entre ellos es que ``MeshComponent" lee los datos de un fichero al crearse y es inmutable, mientras que ``MeshDynamicComponent" se crea asignando una cantidad máxima de vértices e índices y estos se asignan programáticamente, pudiendo modificarse en cualquier momento (será muy importante para la generación dinámica de paredes y ventanas en la sección \ref{walls_holes}). Otra diferencia importante es que ``MeshComponent" puede contener diversas sub-mallas que comparten transformación pero pueden tener distintos materiales, mientras que ``MeshDynamicComponent" solo puede contener una.

\subsubsection{Luces}
Las luces son el elemento más complejo de un motor gráfico. La calidad de la luz es el elemento que más influye en el realismo de la imagen generada, y es uno de los puntos que más coste computacional requiere. En las técnicas de renderizado de alta calidad, se trata de simular la física de la luz para conseguir un gran realismo, pero esto es impracticable en un motor en tiempo real como se ha dicho en el apartado \ref{fps_bucle_ejecucion}.

En el momento de renderizar se utilizan luces para saber con qué intensidad debe renderizarse cada elemento de la escena, o los diferentes puntos de su superficie. Conociendo en qué dirección incide la luz y la normal de la superficie en el punto que queremos pintar, mediante el producto escalar de estos vectores podemos saber si la luz incide sobre este punto y con qué intensidad. Además las luces pueden tener color (normalmente será luz blanca pero no tiene por qué ser así) que se refleja mezclando el color de la luz con el de la superficie.

En la realidad las luces pueden tener formas muy variadas, pero en el motor se reducen a: puntos de luz, luces direccionales, focos, luces de área, luces esféricas y luces cilíndricas. El tipo de luz hará variar el modo en que incide sobre la escena. Las propiedades de esta se asignan en el momento de crear el componente y pueden cambiarse en cualquier momento.

\subsubsection{Cámara}
La cámara indica el punto de vista desde el que se realizará el renderizado de la escena. Existen dos tipos (fig. \ref{fig:camera}):

\begin{itemize}
    \item Cámara ortogonal: se caracteriza por mostrar todos los elementos con la misma escala, sin importar la distancia en que estén. Es especialmente útil para comparar tamaños de distintos elementos, y la utilizaremos para vistas superior y frontales de la habitación, pensados como modos de edición de esta. Sus propiedades son el tamaño, en alto y ancho, de su campo de visión.
    \item Cámara en perspectiva: imita el modo en que vemos los objetos en la realidad, teniendo en cuenta la distancia en que se encuentran. Da resultados mucho más satisfactorios para visualizar la habitación, y transmite más información espacial. Sus propiedades son el ángulo de su campo de visión, más conocido como FOV (field of view), y los planos cercano y lejano de este, comúnmente conocidos como ``near plane" y ``far plane".
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.75]{camera}
    \caption{Diferencias entre una cámara en perspectiva y ortogonal, respectivamente.}
    \label{fig:camera}
\end{figure}

\subsection{Materiales}
\label{materials}
El material de un objeto 3D describe el aspecto que ha de tener la superficie de este en el momento de renderizarlo. Para conseguirlo se asocian una serie de texturas del mismo tamaño y se asocia cada uno de los vértices con coordenadas de dos componentes dentro de estas texturas (conocidas como UV, véase \ref{mesh_light_cam}). Como se explica en el apartado \ref{shaders}, el shader interpola los datos entre dos vértices a cada uno de los píxeles intermedio. De este modo sabiendo la UV que corresponde a cada uno de los vértices podemos saber la que corresponde a cada píxel del objeto 3D.

Las texturas que forman el material pueden ser un color único (que equivale a aplicar una textura de ese color o una imagen importada desde un fichero. El material está formado por los siguientes tipos de texturas o mapas:

\begin{itemize}
    \item Albedo: En el terreno de la física, el albedo es la cantidad de luz que rebota sobre una superficie tras incidir sobre esta\cite{def_albedo}. Puede entenderse como la textura que expresa el color que ha de tener la superficie en cada punto.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.4\linewidth]{material_example/albedo_example}
        \caption{Ejemplo de Albedo\cite{free_pbr}.}
        \label{fig:albedo_ex}
    \end{figure}
    \item Mapa de normales: Habitualmente, la normal de la superficie se expresa a partir de la propia geometría de esta, pero a veces se necesitan ciertos detalles que requerirían aumentar mucho la resolución de la malla, aumentando con ello también el peso del modelo 3D y el coste computacional de procesar y renderizar dicha información. Para evitar esto se puede utilizar una textura de normales: en cada píxel, a la normal de la superficie interpolada a partir de los vértices próximos, le sumamos la normal correspondiente extraída del mapa de normales. Esto permite crear un efecto de profundidad o rugosidad sin modificar la geometría del objeto.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.4\linewidth]{material_example/normal_map_example}
        \caption{Ejemplo de Mapa de Normales\cite{free_pbr}.}
        \label{fig:normal_map_ex}
    \end{figure}
    \item Aspereza (roughness): Se produce cuando la superficie tiene micro-imperfecciones que afectan a los reflejos, haciendo que se difuminen. Cuanto mayor sea la aspereza, más se dispersará la luz al rebotar contra la superficie, y más se difuminará el reflejo; mientras que en una superficie sin imperfecciones la luz se reflejará uniformemente.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.6\linewidth]{material_example/roughness_example}
        \caption{El roughness simula las micro-imperfecciones de la superficie.}
        \label{fig:roughness_ex}
    \end{figure}
    \item Fresnel\footfullcite{marmoset_basicpbr}: El reflejo Fresnel (nombre que hace referencia a su descubridor, Augustin-Jean Fresnel) es la propiedad según la cual los materiales reflejan más cuanto más grande es el ángulo entre la normal de la superfície y la dirección de la luz.
    %\item Reflejo Anisotrópico\cite{anisotropic_ref}: Se produce cuando la superfície tiene imperfecciones organizadas en un patrón, de manera que el ángulo desde el que observamos hace variar el reflejo resultante. Se hace especialmente evidente en metales pulidos, ciertos tejidos, pelo o grandes superficies de agua.
    \item Metalizado\footcite{marmoset_basicpbr}: Los metales tienden a reflejar la luz, razón por la que se define un valor de metalizado para especificar la cantidad de luz que refleja una superficie. Con el metalizado también se puede definir un tinte para la luz reflejada (por ejemplo, reflejos amarillentos en la superficie del oro).
    \item Oclusión ambiental\footfullcite{ambient_occlusion}: Se trata de un efecto del que a menudo se abusa, dado que no existe en la realidad. El mapa de oclusión permite oscurecer ciertas zonas de la geometría, normalmente los puntos que forman ángulos más cerrados. Resulta efectivo para imitar ciertas sombras que se producen en estos puntos, pero en exceso puede resultar artificial.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.4\linewidth]{material_example/ambient_occlussion_example}
        \caption{Ejemplo de mapa de oclusión ambiental.}
        \label{fig:occlusion_ex}
    \end{figure}
\end{itemize}

\subsection{Gestión de memoria}
\label{engine_memory}
Una de las operaciones que más tiempo demandan en C++ es solicitar nueva memoria al sistema operativo. Debido a eso, abusar de las asignaciones de memoria, por ejemplo haciéndolas dentro de bucles (como el bucle de Manta), puede hacer que el programa se ralentice considerablemente.

Para minimizar la cantidad de asignaciones que realizamos, manta tiene un único ``bloque de memoria" (más conocido como Memory Pool). El Memory Pool asigna una gran cantidad de memoria al inicializar el programa y nos da acceso a esta cada vez que lo necesitemos. Hacer esto es más barato computacionalmente, de modo que no necesitamos preocuparnos de las asignaciones que necesitemos hacer. También nos proporciona un tiempo constante de reserva y liberación de memoria.

Dada la cantidad de memoria que se necesita para una variable, el Memory Pool automáticamente busca una región del bloque no esté siendo utilizada en ese momento y devuelve un puntero a esa región, marcándola como ``usada" desde ese momento. Cuando la variable deje de ser necesaria, podemos liberarla para futuras operaciones. Eso provoca que a lo largo de la ejecución puedan quedar pequeños fragmentos del bloque de memoria sin utilizar, que no siempre serán útiles para nuevos usos; algunas implementaciones de Memory Pool pueden reorganizar la memoria utilizada para evitar que queden estos fragmentos, pero hacerlo tiene un mayor coste computacional e impide que el programador trabaje directamente con punteros al bloque de memoria (dado que al reorganizar dichos punteros dejarían de ser válidos), obligando a usar sistemas más complicados de punteros.

Sin embargo, existen dos desventajas importantes:

Por un lado necesitamos saber desde el principio cuánta memoria podemos llegar a necesitar dado que esta solo se va a asignar una vez; en caso de superar ese límite de memoria tendremos un error de segmentación que detendrá el programa.

Por otro lado, también necesitamos tener mucho más cuidado con la memoria que solicitemos al Memory Pool: si nos equivocamos al manejar la memoria asignada, C++ suele responder con un error de segmentación; pero si hacemos lo mismo con la memoria del Memory Pool, ese error no se producirá y estaremos modificando datos que corresponden a otras variables. Al fin y al cabo, el puntero que recibimos apunta a una posición desconocida del Memory Pool, y nada nos impide desplazarnos por este sin tener en cuenta el tamaño de la memoria que nos ha asignado.

En la figura \ref{fig:memory_pool} se puede ver un ejemplo de como podría quedar la memoria en mitad de una ejecución mientras se solicita un bloque del tamaño de un float. Cada cuadrado representa un byte de información.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{MemoryPool}
    \caption{Ejemplo de una posible distribución del Memory Pool durante una ejecución.}
    \label{fig:memory_pool}
\end{figure}

\subsection{Gestión de identificadores}
\label{manta_id_management}
Entender como funcionan los identificadores en el motor Manta será un detalle importante en algunos puntos de este documento. Cada vez que se ordena a la API gráfica cargar un asset, esta devuelve un identificador que permite indicar posteriormente lo que se quiere hacer con los datos cargados en memoria. Sin embargo, este identificador no es el que se obtiene desde fuera del motor.

Manta crea una capa de abstracción por encima de los identificadores de la API gráfica, para evitar que sean manipulados desde fuera del motor. Desde Manta se espera tener constancia del estado de todos los assets por lo dar el identificador que proporciona la API gráfica permitiría al programador realizar ciertos ``hacks" que harían que Manta perdiera el rastro de los assets.

Por otro lado, generar los propios identificadores de Manta permite mantener la consistencia entre diferentes APIs gráficas y otros elementos del motor. No sólo se busca impedir al programador manipular la API gráfica sino que también se espera que no sea necesario en ningún caso y el mantener esta consistencia hace más sencillo trabajar con el motor.
